{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Desktop\\galaxy_catalogue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u-g</th>\n",
       "      <th>g-r</th>\n",
       "      <th>r-i</th>\n",
       "      <th>i-z</th>\n",
       "      <th>ecc</th>\n",
       "      <th>m4_u</th>\n",
       "      <th>m4_g</th>\n",
       "      <th>m4_r</th>\n",
       "      <th>m4_i</th>\n",
       "      <th>m4_z</th>\n",
       "      <th>petroR50_u</th>\n",
       "      <th>petroR50_r</th>\n",
       "      <th>petroR50_z</th>\n",
       "      <th>petroR90_u</th>\n",
       "      <th>petroR90_r</th>\n",
       "      <th>petroR90_z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.85765</td>\n",
       "      <td>0.67158</td>\n",
       "      <td>0.42310</td>\n",
       "      <td>0.30610</td>\n",
       "      <td>0.585428</td>\n",
       "      <td>2.251946</td>\n",
       "      <td>2.339849</td>\n",
       "      <td>2.380652</td>\n",
       "      <td>2.359738</td>\n",
       "      <td>2.395528</td>\n",
       "      <td>3.095123</td>\n",
       "      <td>3.818919</td>\n",
       "      <td>3.826230</td>\n",
       "      <td>5.174814</td>\n",
       "      <td>8.263009</td>\n",
       "      <td>11.477340</td>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.74259</td>\n",
       "      <td>0.86085</td>\n",
       "      <td>0.44927</td>\n",
       "      <td>0.28851</td>\n",
       "      <td>0.749812</td>\n",
       "      <td>2.031566</td>\n",
       "      <td>2.084156</td>\n",
       "      <td>2.092272</td>\n",
       "      <td>2.124075</td>\n",
       "      <td>2.133154</td>\n",
       "      <td>1.430436</td>\n",
       "      <td>1.422533</td>\n",
       "      <td>1.385727</td>\n",
       "      <td>3.732712</td>\n",
       "      <td>3.416921</td>\n",
       "      <td>3.330347</td>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.10697</td>\n",
       "      <td>0.96710</td>\n",
       "      <td>0.56810</td>\n",
       "      <td>0.33747</td>\n",
       "      <td>0.630089</td>\n",
       "      <td>1.992887</td>\n",
       "      <td>2.450746</td>\n",
       "      <td>2.473116</td>\n",
       "      <td>2.465324</td>\n",
       "      <td>2.438683</td>\n",
       "      <td>3.099957</td>\n",
       "      <td>3.623704</td>\n",
       "      <td>3.463300</td>\n",
       "      <td>9.110857</td>\n",
       "      <td>8.354343</td>\n",
       "      <td>11.265390</td>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.22840</td>\n",
       "      <td>0.60446</td>\n",
       "      <td>0.39049</td>\n",
       "      <td>0.28913</td>\n",
       "      <td>0.668999</td>\n",
       "      <td>2.056115</td>\n",
       "      <td>2.182252</td>\n",
       "      <td>2.309510</td>\n",
       "      <td>2.391414</td>\n",
       "      <td>2.472397</td>\n",
       "      <td>3.627267</td>\n",
       "      <td>4.063471</td>\n",
       "      <td>3.717708</td>\n",
       "      <td>9.580675</td>\n",
       "      <td>12.202420</td>\n",
       "      <td>11.826220</td>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.80792</td>\n",
       "      <td>0.78124</td>\n",
       "      <td>0.45528</td>\n",
       "      <td>0.35067</td>\n",
       "      <td>0.500170</td>\n",
       "      <td>2.259167</td>\n",
       "      <td>2.194723</td>\n",
       "      <td>2.264567</td>\n",
       "      <td>2.334713</td>\n",
       "      <td>2.352568</td>\n",
       "      <td>3.256751</td>\n",
       "      <td>3.153533</td>\n",
       "      <td>2.254511</td>\n",
       "      <td>9.206746</td>\n",
       "      <td>9.790146</td>\n",
       "      <td>6.636931</td>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u-g      g-r      r-i      i-z       ecc      m4_u      m4_g      m4_r  \\\n",
       "0  1.85765  0.67158  0.42310  0.30610  0.585428  2.251946  2.339849  2.380652   \n",
       "1  1.74259  0.86085  0.44927  0.28851  0.749812  2.031566  2.084156  2.092272   \n",
       "2  2.10697  0.96710  0.56810  0.33747  0.630089  1.992887  2.450746  2.473116   \n",
       "3  1.22840  0.60446  0.39049  0.28913  0.668999  2.056115  2.182252  2.309510   \n",
       "4  1.80792  0.78124  0.45528  0.35067  0.500170  2.259167  2.194723  2.264567   \n",
       "\n",
       "       m4_i      m4_z  petroR50_u  petroR50_r  petroR50_z  petroR90_u  \\\n",
       "0  2.359738  2.395528    3.095123    3.818919    3.826230    5.174814   \n",
       "1  2.124075  2.133154    1.430436    1.422533    1.385727    3.732712   \n",
       "2  2.465324  2.438683    3.099957    3.623704    3.463300    9.110857   \n",
       "3  2.391414  2.472397    3.627267    4.063471    3.717708    9.580675   \n",
       "4  2.334713  2.352568    3.256751    3.153533    2.254511    9.206746   \n",
       "\n",
       "   petroR90_r  petroR90_z   class  \n",
       "0    8.263009   11.477340  merger  \n",
       "1    3.416921    3.330347  merger  \n",
       "2    8.354343   11.265390  merger  \n",
       "3   12.202420   11.826220  merger  \n",
       "4    9.790146    6.636931  merger  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u-g</th>\n",
       "      <th>g-r</th>\n",
       "      <th>r-i</th>\n",
       "      <th>i-z</th>\n",
       "      <th>ecc</th>\n",
       "      <th>m4_u</th>\n",
       "      <th>m4_g</th>\n",
       "      <th>m4_r</th>\n",
       "      <th>m4_i</th>\n",
       "      <th>m4_z</th>\n",
       "      <th>petroR50_u</th>\n",
       "      <th>petroR50_r</th>\n",
       "      <th>petroR50_z</th>\n",
       "      <th>petroR90_u</th>\n",
       "      <th>petroR90_r</th>\n",
       "      <th>petroR90_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.633556</td>\n",
       "      <td>0.751285</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.256630</td>\n",
       "      <td>0.713827</td>\n",
       "      <td>-36.228336</td>\n",
       "      <td>-10.499354</td>\n",
       "      <td>-23.280043</td>\n",
       "      <td>-36.084795</td>\n",
       "      <td>-48.904677</td>\n",
       "      <td>-46.026529</td>\n",
       "      <td>4.897747</td>\n",
       "      <td>-34.147368</td>\n",
       "      <td>-38.642822</td>\n",
       "      <td>12.625589</td>\n",
       "      <td>-27.091879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.333986</td>\n",
       "      <td>0.094902</td>\n",
       "      <td>0.434369</td>\n",
       "      <td>0.171010</td>\n",
       "      <td>619.454396</td>\n",
       "      <td>358.104842</td>\n",
       "      <td>506.113635</td>\n",
       "      <td>619.462662</td>\n",
       "      <td>714.833597</td>\n",
       "      <td>715.052758</td>\n",
       "      <td>5.647410</td>\n",
       "      <td>619.598004</td>\n",
       "      <td>715.634265</td>\n",
       "      <td>9.482342</td>\n",
       "      <td>620.075967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.202350</td>\n",
       "      <td>-4.708600</td>\n",
       "      <td>-0.630590</td>\n",
       "      <td>-7.698340</td>\n",
       "      <td>0.226894</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>0.617535</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>1.031904</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.333080</td>\n",
       "      <td>0.620432</td>\n",
       "      <td>0.353687</td>\n",
       "      <td>0.227997</td>\n",
       "      <td>0.592427</td>\n",
       "      <td>2.124926</td>\n",
       "      <td>2.238136</td>\n",
       "      <td>2.303345</td>\n",
       "      <td>2.327275</td>\n",
       "      <td>2.329166</td>\n",
       "      <td>2.896251</td>\n",
       "      <td>2.884019</td>\n",
       "      <td>2.553682</td>\n",
       "      <td>7.056056</td>\n",
       "      <td>8.101448</td>\n",
       "      <td>7.145191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.701755</td>\n",
       "      <td>0.789610</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>0.294780</td>\n",
       "      <td>0.744386</td>\n",
       "      <td>2.269386</td>\n",
       "      <td>2.351759</td>\n",
       "      <td>2.380019</td>\n",
       "      <td>2.394285</td>\n",
       "      <td>2.390121</td>\n",
       "      <td>4.391504</td>\n",
       "      <td>3.929862</td>\n",
       "      <td>3.449929</td>\n",
       "      <td>10.743275</td>\n",
       "      <td>10.509180</td>\n",
       "      <td>9.423079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.914082</td>\n",
       "      <td>0.905282</td>\n",
       "      <td>0.430363</td>\n",
       "      <td>0.326920</td>\n",
       "      <td>0.852673</td>\n",
       "      <td>2.390789</td>\n",
       "      <td>2.420319</td>\n",
       "      <td>2.439145</td>\n",
       "      <td>2.448875</td>\n",
       "      <td>2.449683</td>\n",
       "      <td>6.148377</td>\n",
       "      <td>5.450743</td>\n",
       "      <td>4.832378</td>\n",
       "      <td>14.975497</td>\n",
       "      <td>14.321407</td>\n",
       "      <td>13.388955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.624040</td>\n",
       "      <td>1.539170</td>\n",
       "      <td>1.390840</td>\n",
       "      <td>4.879330</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>26.009380</td>\n",
       "      <td>2.724017</td>\n",
       "      <td>2.737767</td>\n",
       "      <td>2.728628</td>\n",
       "      <td>2.730472</td>\n",
       "      <td>61.133380</td>\n",
       "      <td>134.394700</td>\n",
       "      <td>89.220090</td>\n",
       "      <td>112.493900</td>\n",
       "      <td>162.428100</td>\n",
       "      <td>116.535700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              u-g         g-r         r-i         i-z         ecc  \\\n",
       "count  780.000000  780.000000  780.000000  780.000000  780.000000   \n",
       "mean     1.633556    0.751285    0.390027    0.256630    0.713827   \n",
       "std      0.680241    0.333986    0.094902    0.434369    0.171010   \n",
       "min     -8.202350   -4.708600   -0.630590   -7.698340    0.226894   \n",
       "25%      1.333080    0.620432    0.353687    0.227997    0.592427   \n",
       "50%      1.701755    0.789610    0.400985    0.294780    0.744386   \n",
       "75%      1.914082    0.905282    0.430363    0.326920    0.852673   \n",
       "max     10.624040    1.539170    1.390840    4.879330    0.999812   \n",
       "\n",
       "              m4_u         m4_g         m4_r         m4_i         m4_z  \\\n",
       "count   780.000000   780.000000   780.000000   780.000000   780.000000   \n",
       "mean    -36.228336   -10.499354   -23.280043   -36.084795   -48.904677   \n",
       "std     619.454396   358.104842   506.113635   619.462662   714.833597   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       2.124926     2.238136     2.303345     2.327275     2.329166   \n",
       "50%       2.269386     2.351759     2.380019     2.394285     2.390121   \n",
       "75%       2.390789     2.420319     2.439145     2.448875     2.449683   \n",
       "max      26.009380     2.724017     2.737767     2.728628     2.730472   \n",
       "\n",
       "        petroR50_u  petroR50_r   petroR50_z   petroR90_u  petroR90_r  \\\n",
       "count   780.000000  780.000000   780.000000   780.000000  780.000000   \n",
       "mean    -46.026529    4.897747   -34.147368   -38.642822   12.625589   \n",
       "std     715.052758    5.647410   619.598004   715.634265    9.482342   \n",
       "min   -9999.000000    0.617535 -9999.000000 -9999.000000    1.031904   \n",
       "25%       2.896251    2.884019     2.553682     7.056056    8.101448   \n",
       "50%       4.391504    3.929862     3.449929    10.743275   10.509180   \n",
       "75%       6.148377    5.450743     4.832378    14.975497   14.321407   \n",
       "max      61.133380  134.394700    89.220090   112.493900  162.428100   \n",
       "\n",
       "        petroR90_z  \n",
       "count   780.000000  \n",
       "mean    -27.091879  \n",
       "std     620.075967  \n",
       "min   -9999.000000  \n",
       "25%       7.145191  \n",
       "50%       9.423079  \n",
       "75%      13.388955  \n",
       "max     116.535700  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:10]\n",
    "y=dataset['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 =y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = pd.DataFrame(y2)\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['conc_u']=(dataset['petroR50_u'])/(dataset['petroR90_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['conc_r']=dataset['petroR50_r']/dataset['petroR90_r']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['conc_z']= dataset['petroR50_z']/dataset['petroR90_z']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcf444b7828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spiral'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    merger\n",
       "1    merger\n",
       "2    merger\n",
       "3    merger\n",
       "4    merger\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class\n",
       "0  merger\n",
       "1  merger\n",
       "2  merger\n",
       "3  merger\n",
       "4  merger"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'merger':0,'elliptical':1,'spiral':2}\n",
    "y_train = y_train.iloc[:,0].map(space)\n",
    "y_train = to_categorical(y_train,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# intialising the ann\n",
    "classifier = Sequential()\n",
    "\n",
    "#adding input layer,hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init='uniform' , activation = 'relu' , input_dim= 13))\n",
    "\n",
    "classifier.add(Dense(output_dim = 32, init='uniform' , activation = 'relu' ))\n",
    "\n",
    "#adding output layer\n",
    "classifier.add(Dense(output_dim = 3, init='uniform' , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 407\n",
      "Trainable params: 407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "624/624 [==============================] - 1s 2ms/step - loss: 1.0888 - accuracy: 0.4696\n",
      "Epoch 2/200\n",
      "624/624 [==============================] - 0s 487us/step - loss: 0.9372 - accuracy: 0.7035\n",
      "Epoch 3/200\n",
      "624/624 [==============================] - 0s 361us/step - loss: 0.7380 - accuracy: 0.6955\n",
      "Epoch 4/200\n",
      "624/624 [==============================] - 0s 390us/step - loss: 0.6198 - accuracy: 0.7532\n",
      "Epoch 5/200\n",
      "624/624 [==============================] - 0s 370us/step - loss: 0.5524 - accuracy: 0.7837\n",
      "Epoch 6/200\n",
      "624/624 [==============================] - 0s 447us/step - loss: 0.5133 - accuracy: 0.7997\n",
      "Epoch 7/200\n",
      "624/624 [==============================] - 0s 407us/step - loss: 0.4880 - accuracy: 0.8077\n",
      "Epoch 8/200\n",
      "624/624 [==============================] - 0s 345us/step - loss: 0.4735 - accuracy: 0.8141\n",
      "Epoch 9/200\n",
      "624/624 [==============================] - 0s 361us/step - loss: 0.4652 - accuracy: 0.8157\n",
      "Epoch 10/200\n",
      "624/624 [==============================] - 0s 386us/step - loss: 0.4605 - accuracy: 0.8173\n",
      "Epoch 11/200\n",
      "624/624 [==============================] - 0s 385us/step - loss: 0.4573 - accuracy: 0.8173\n",
      "Epoch 12/200\n",
      "624/624 [==============================] - 0s 407us/step - loss: 0.4498 - accuracy: 0.8301\n",
      "Epoch 13/200\n",
      "624/624 [==============================] - 0s 327us/step - loss: 0.4453 - accuracy: 0.8301\n",
      "Epoch 14/200\n",
      "624/624 [==============================] - 0s 295us/step - loss: 0.4432 - accuracy: 0.8301\n",
      "Epoch 15/200\n",
      "624/624 [==============================] - 0s 330us/step - loss: 0.4395 - accuracy: 0.8381\n",
      "Epoch 16/200\n",
      "624/624 [==============================] - 0s 318us/step - loss: 0.4362 - accuracy: 0.8349\n",
      "Epoch 17/200\n",
      "624/624 [==============================] - 0s 356us/step - loss: 0.4339 - accuracy: 0.8365\n",
      "Epoch 18/200\n",
      "624/624 [==============================] - 0s 351us/step - loss: 0.4307 - accuracy: 0.8349\n",
      "Epoch 19/200\n",
      "624/624 [==============================] - 0s 283us/step - loss: 0.4318 - accuracy: 0.8317\n",
      "Epoch 20/200\n",
      "624/624 [==============================] - 0s 281us/step - loss: 0.4271 - accuracy: 0.8365\n",
      "Epoch 21/200\n",
      "624/624 [==============================] - 0s 285us/step - loss: 0.4238 - accuracy: 0.8429\n",
      "Epoch 22/200\n",
      "624/624 [==============================] - 0s 287us/step - loss: 0.4213 - accuracy: 0.8397\n",
      "Epoch 23/200\n",
      "624/624 [==============================] - 0s 329us/step - loss: 0.4189 - accuracy: 0.8446\n",
      "Epoch 24/200\n",
      "624/624 [==============================] - 0s 334us/step - loss: 0.4205 - accuracy: 0.8365\n",
      "Epoch 25/200\n",
      "624/624 [==============================] - 0s 241us/step - loss: 0.4183 - accuracy: 0.8397\n",
      "Epoch 26/200\n",
      "624/624 [==============================] - 0s 242us/step - loss: 0.4142 - accuracy: 0.8413\n",
      "Epoch 27/200\n",
      "624/624 [==============================] - 0s 245us/step - loss: 0.4151 - accuracy: 0.8397\n",
      "Epoch 28/200\n",
      "624/624 [==============================] - 0s 281us/step - loss: 0.4138 - accuracy: 0.8413\n",
      "Epoch 29/200\n",
      "624/624 [==============================] - 0s 271us/step - loss: 0.4105 - accuracy: 0.8429\n",
      "Epoch 30/200\n",
      "624/624 [==============================] - 0s 286us/step - loss: 0.4093 - accuracy: 0.8397\n",
      "Epoch 31/200\n",
      "624/624 [==============================] - 0s 314us/step - loss: 0.4070 - accuracy: 0.8446\n",
      "Epoch 32/200\n",
      "624/624 [==============================] - 0s 274us/step - loss: 0.4062 - accuracy: 0.8462\n",
      "Epoch 33/200\n",
      "624/624 [==============================] - 0s 269us/step - loss: 0.4044 - accuracy: 0.8446\n",
      "Epoch 34/200\n",
      "624/624 [==============================] - 0s 265us/step - loss: 0.4012 - accuracy: 0.8446\n",
      "Epoch 35/200\n",
      "624/624 [==============================] - 0s 282us/step - loss: 0.3994 - accuracy: 0.8462\n",
      "Epoch 36/200\n",
      "624/624 [==============================] - 0s 260us/step - loss: 0.3988 - accuracy: 0.8478\n",
      "Epoch 37/200\n",
      "624/624 [==============================] - 0s 300us/step - loss: 0.3962 - accuracy: 0.8478\n",
      "Epoch 38/200\n",
      "624/624 [==============================] - 0s 245us/step - loss: 0.3952 - accuracy: 0.8462\n",
      "Epoch 39/200\n",
      "624/624 [==============================] - 0s 226us/step - loss: 0.3947 - accuracy: 0.8478\n",
      "Epoch 40/200\n",
      "624/624 [==============================] - 0s 236us/step - loss: 0.3921 - accuracy: 0.8494\n",
      "Epoch 41/200\n",
      "624/624 [==============================] - 0s 233us/step - loss: 0.3902 - accuracy: 0.8462\n",
      "Epoch 42/200\n",
      "624/624 [==============================] - 0s 229us/step - loss: 0.3890 - accuracy: 0.8478\n",
      "Epoch 43/200\n",
      "624/624 [==============================] - 0s 245us/step - loss: 0.3874 - accuracy: 0.8462\n",
      "Epoch 44/200\n",
      "624/624 [==============================] - 0s 242us/step - loss: 0.3843 - accuracy: 0.8510\n",
      "Epoch 45/200\n",
      "624/624 [==============================] - 0s 282us/step - loss: 0.3821 - accuracy: 0.8494\n",
      "Epoch 46/200\n",
      "624/624 [==============================] - 0s 237us/step - loss: 0.3830 - accuracy: 0.8494\n",
      "Epoch 47/200\n",
      "624/624 [==============================] - 0s 202us/step - loss: 0.3786 - accuracy: 0.8494\n",
      "Epoch 48/200\n",
      "624/624 [==============================] - 0s 212us/step - loss: 0.3845 - accuracy: 0.8494\n",
      "Epoch 49/200\n",
      "624/624 [==============================] - 0s 225us/step - loss: 0.3796 - accuracy: 0.8494\n",
      "Epoch 50/200\n",
      "624/624 [==============================] - 0s 229us/step - loss: 0.3742 - accuracy: 0.8462\n",
      "Epoch 51/200\n",
      "624/624 [==============================] - 0s 241us/step - loss: 0.3743 - accuracy: 0.8494\n",
      "Epoch 52/200\n",
      "624/624 [==============================] - 0s 236us/step - loss: 0.3738 - accuracy: 0.8478\n",
      "Epoch 53/200\n",
      "624/624 [==============================] - 0s 228us/step - loss: 0.3742 - accuracy: 0.8510\n",
      "Epoch 54/200\n",
      "624/624 [==============================] - 0s 189us/step - loss: 0.3715 - accuracy: 0.8446\n",
      "Epoch 55/200\n",
      "624/624 [==============================] - 0s 186us/step - loss: 0.3693 - accuracy: 0.8478\n",
      "Epoch 56/200\n",
      "624/624 [==============================] - 0s 182us/step - loss: 0.3658 - accuracy: 0.8510\n",
      "Epoch 57/200\n",
      "624/624 [==============================] - 0s 181us/step - loss: 0.3665 - accuracy: 0.8494\n",
      "Epoch 58/200\n",
      "624/624 [==============================] - 0s 180us/step - loss: 0.3657 - accuracy: 0.8462\n",
      "Epoch 59/200\n",
      "624/624 [==============================] - 0s 186us/step - loss: 0.3636 - accuracy: 0.8526\n",
      "Epoch 60/200\n",
      "624/624 [==============================] - 0s 178us/step - loss: 0.3637 - accuracy: 0.8526\n",
      "Epoch 61/200\n",
      "624/624 [==============================] - 0s 204us/step - loss: 0.3645 - accuracy: 0.8494\n",
      "Epoch 62/200\n",
      "624/624 [==============================] - 0s 231us/step - loss: 0.3604 - accuracy: 0.8510\n",
      "Epoch 63/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3583 - accuracy: 0.8542\n",
      "Epoch 64/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3565 - accuracy: 0.8526\n",
      "Epoch 65/200\n",
      "624/624 [==============================] - 0s 121us/step - loss: 0.3597 - accuracy: 0.8542\n",
      "Epoch 66/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3578 - accuracy: 0.8526\n",
      "Epoch 67/200\n",
      "624/624 [==============================] - 0s 132us/step - loss: 0.3554 - accuracy: 0.8574\n",
      "Epoch 68/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3543 - accuracy: 0.8510\n",
      "Epoch 69/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3555 - accuracy: 0.8590\n",
      "Epoch 70/200\n",
      "624/624 [==============================] - 0s 127us/step - loss: 0.3538 - accuracy: 0.8542\n",
      "Epoch 71/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3530 - accuracy: 0.8462\n",
      "Epoch 72/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3509 - accuracy: 0.8606\n",
      "Epoch 73/200\n",
      "624/624 [==============================] - 0s 127us/step - loss: 0.3499 - accuracy: 0.8622\n",
      "Epoch 74/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3482 - accuracy: 0.8526\n",
      "Epoch 75/200\n",
      "624/624 [==============================] - 0s 157us/step - loss: 0.3484 - accuracy: 0.8574\n",
      "Epoch 76/200\n",
      "624/624 [==============================] - 0s 117us/step - loss: 0.3469 - accuracy: 0.8574\n",
      "Epoch 77/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3500 - accuracy: 0.8526\n",
      "Epoch 78/200\n",
      "624/624 [==============================] - 0s 127us/step - loss: 0.3470 - accuracy: 0.8590\n",
      "Epoch 79/200\n",
      "624/624 [==============================] - 0s 117us/step - loss: 0.3468 - accuracy: 0.8574\n",
      "Epoch 80/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3457 - accuracy: 0.8526\n",
      "Epoch 81/200\n",
      "624/624 [==============================] - 0s 119us/step - loss: 0.3442 - accuracy: 0.8574\n",
      "Epoch 82/200\n",
      "624/624 [==============================] - 0s 115us/step - loss: 0.3456 - accuracy: 0.8558\n",
      "Epoch 83/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3438 - accuracy: 0.8542\n",
      "Epoch 84/200\n",
      "624/624 [==============================] - 0s 119us/step - loss: 0.3442 - accuracy: 0.8574\n",
      "Epoch 85/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3449 - accuracy: 0.8638\n",
      "Epoch 86/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3432 - accuracy: 0.8574\n",
      "Epoch 87/200\n",
      "624/624 [==============================] - 0s 119us/step - loss: 0.3392 - accuracy: 0.8606\n",
      "Epoch 88/200\n",
      "624/624 [==============================] - 0s 154us/step - loss: 0.3383 - accuracy: 0.8574\n",
      "Epoch 89/200\n",
      "624/624 [==============================] - 0s 133us/step - loss: 0.3378 - accuracy: 0.8590\n",
      "Epoch 90/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3412 - accuracy: 0.8574\n",
      "Epoch 91/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3390 - accuracy: 0.8590\n",
      "Epoch 92/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3380 - accuracy: 0.8590\n",
      "Epoch 93/200\n",
      "624/624 [==============================] - 0s 124us/step - loss: 0.3382 - accuracy: 0.8590\n",
      "Epoch 94/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3375 - accuracy: 0.8590\n",
      "Epoch 95/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3428 - accuracy: 0.8558\n",
      "Epoch 96/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3380 - accuracy: 0.8606\n",
      "Epoch 97/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3379 - accuracy: 0.8574\n",
      "Epoch 98/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3348 - accuracy: 0.8574\n",
      "Epoch 99/200\n",
      "624/624 [==============================] - 0s 119us/step - loss: 0.3352 - accuracy: 0.8670\n",
      "Epoch 100/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3343 - accuracy: 0.8542\n",
      "Epoch 101/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3333 - accuracy: 0.8654\n",
      "Epoch 102/200\n",
      "624/624 [==============================] - 0s 172us/step - loss: 0.3360 - accuracy: 0.8558\n",
      "Epoch 103/200\n",
      "624/624 [==============================] - 0s 143us/step - loss: 0.3338 - accuracy: 0.8622\n",
      "Epoch 104/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3328 - accuracy: 0.8622\n",
      "Epoch 105/200\n",
      "624/624 [==============================] - 0s 148us/step - loss: 0.3324 - accuracy: 0.8670\n",
      "Epoch 106/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3339 - accuracy: 0.8670\n",
      "Epoch 107/200\n",
      "624/624 [==============================] - 0s 144us/step - loss: 0.3313 - accuracy: 0.8638\n",
      "Epoch 108/200\n",
      "624/624 [==============================] - 0s 160us/step - loss: 0.3343 - accuracy: 0.8654\n",
      "Epoch 109/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3339 - accuracy: 0.8654\n",
      "Epoch 110/200\n",
      "624/624 [==============================] - 0s 159us/step - loss: 0.3317 - accuracy: 0.8606\n",
      "Epoch 111/200\n",
      "624/624 [==============================] - 0s 152us/step - loss: 0.3299 - accuracy: 0.8622\n",
      "Epoch 112/200\n",
      "624/624 [==============================] - 0s 149us/step - loss: 0.3300 - accuracy: 0.8606\n",
      "Epoch 113/200\n",
      "624/624 [==============================] - 0s 204us/step - loss: 0.3332 - accuracy: 0.8638\n",
      "Epoch 114/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3299 - accuracy: 0.8590\n",
      "Epoch 115/200\n",
      "624/624 [==============================] - 0s 133us/step - loss: 0.3309 - accuracy: 0.8654\n",
      "Epoch 116/200\n",
      "624/624 [==============================] - 0s 149us/step - loss: 0.3295 - accuracy: 0.8622\n",
      "Epoch 117/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3286 - accuracy: 0.8702\n",
      "Epoch 118/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3295 - accuracy: 0.8670\n",
      "Epoch 119/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3323 - accuracy: 0.8654\n",
      "Epoch 120/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3286 - accuracy: 0.8638\n",
      "Epoch 121/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3269 - accuracy: 0.8654\n",
      "Epoch 122/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3279 - accuracy: 0.8574\n",
      "Epoch 123/200\n",
      "624/624 [==============================] - 0s 129us/step - loss: 0.3292 - accuracy: 0.8590\n",
      "Epoch 124/200\n",
      "624/624 [==============================] - 0s 120us/step - loss: 0.3248 - accuracy: 0.8702\n",
      "Epoch 125/200\n",
      "624/624 [==============================] - 0s 173us/step - loss: 0.3266 - accuracy: 0.8686\n",
      "Epoch 126/200\n",
      "624/624 [==============================] - 0s 141us/step - loss: 0.3268 - accuracy: 0.8654\n",
      "Epoch 127/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3294 - accuracy: 0.8558\n",
      "Epoch 128/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3292 - accuracy: 0.8638\n",
      "Epoch 129/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3260 - accuracy: 0.8558\n",
      "Epoch 130/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3244 - accuracy: 0.8702\n",
      "Epoch 131/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3285 - accuracy: 0.8638\n",
      "Epoch 132/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3237 - accuracy: 0.8702\n",
      "Epoch 133/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3241 - accuracy: 0.8718\n",
      "Epoch 134/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3264 - accuracy: 0.8638\n",
      "Epoch 135/200\n",
      "624/624 [==============================] - 0s 132us/step - loss: 0.3232 - accuracy: 0.8686\n",
      "Epoch 136/200\n",
      "624/624 [==============================] - 0s 127us/step - loss: 0.3240 - accuracy: 0.8670\n",
      "Epoch 137/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3261 - accuracy: 0.8606\n",
      "Epoch 138/200\n",
      "624/624 [==============================] - 0s 167us/step - loss: 0.3244 - accuracy: 0.8718\n",
      "Epoch 139/200\n",
      "624/624 [==============================] - 0s 133us/step - loss: 0.3219 - accuracy: 0.8686\n",
      "Epoch 140/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3236 - accuracy: 0.8654\n",
      "Epoch 141/200\n",
      "624/624 [==============================] - 0s 123us/step - loss: 0.3204 - accuracy: 0.8686\n",
      "Epoch 142/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3221 - accuracy: 0.8606\n",
      "Epoch 143/200\n",
      "624/624 [==============================] - 0s 148us/step - loss: 0.3202 - accuracy: 0.8654\n",
      "Epoch 144/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3234 - accuracy: 0.8670\n",
      "Epoch 145/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3208 - accuracy: 0.8702\n",
      "Epoch 146/200\n",
      "624/624 [==============================] - 0s 141us/step - loss: 0.3186 - accuracy: 0.8670\n",
      "Epoch 147/200\n",
      "624/624 [==============================] - 0s 122us/step - loss: 0.3194 - accuracy: 0.8606\n",
      "Epoch 148/200\n",
      "624/624 [==============================] - 0s 143us/step - loss: 0.3167 - accuracy: 0.8702\n",
      "Epoch 149/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3191 - accuracy: 0.8638\n",
      "Epoch 150/200\n",
      "624/624 [==============================] - 0s 188us/step - loss: 0.3206 - accuracy: 0.8606\n",
      "Epoch 151/200\n",
      "624/624 [==============================] - 0s 136us/step - loss: 0.3188 - accuracy: 0.8702\n",
      "Epoch 152/200\n",
      "624/624 [==============================] - 0s 141us/step - loss: 0.3195 - accuracy: 0.8670\n",
      "Epoch 153/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3191 - accuracy: 0.8686\n",
      "Epoch 154/200\n",
      "624/624 [==============================] - 0s 151us/step - loss: 0.3195 - accuracy: 0.8670\n",
      "Epoch 155/200\n",
      "624/624 [==============================] - 0s 148us/step - loss: 0.3159 - accuracy: 0.8718\n",
      "Epoch 156/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3221 - accuracy: 0.8734\n",
      "Epoch 157/200\n",
      "624/624 [==============================] - 0s 134us/step - loss: 0.3195 - accuracy: 0.8718\n",
      "Epoch 158/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3189 - accuracy: 0.8606\n",
      "Epoch 159/200\n",
      "624/624 [==============================] - 0s 130us/step - loss: 0.3185 - accuracy: 0.8670\n",
      "Epoch 160/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3157 - accuracy: 0.8670\n",
      "Epoch 161/200\n",
      "624/624 [==============================] - 0s 157us/step - loss: 0.3169 - accuracy: 0.8686\n",
      "Epoch 162/200\n",
      "624/624 [==============================] - 0s 189us/step - loss: 0.3201 - accuracy: 0.8638\n",
      "Epoch 163/200\n",
      "624/624 [==============================] - 0s 144us/step - loss: 0.3187 - accuracy: 0.8686\n",
      "Epoch 164/200\n",
      "624/624 [==============================] - 0s 135us/step - loss: 0.3151 - accuracy: 0.8670\n",
      "Epoch 165/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3156 - accuracy: 0.8638\n",
      "Epoch 166/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3154 - accuracy: 0.8702\n",
      "Epoch 167/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3154 - accuracy: 0.8654\n",
      "Epoch 168/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3188 - accuracy: 0.8750\n",
      "Epoch 169/200\n",
      "624/624 [==============================] - 0s 148us/step - loss: 0.3156 - accuracy: 0.8622\n",
      "Epoch 170/200\n",
      "624/624 [==============================] - 0s 168us/step - loss: 0.3147 - accuracy: 0.8686\n",
      "Epoch 171/200\n",
      "624/624 [==============================] - 0s 144us/step - loss: 0.3147 - accuracy: 0.8702\n",
      "Epoch 172/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3168 - accuracy: 0.8654\n",
      "Epoch 173/200\n",
      "624/624 [==============================] - 0s 159us/step - loss: 0.3173 - accuracy: 0.8718\n",
      "Epoch 174/200\n",
      "624/624 [==============================] - 0s 156us/step - loss: 0.3146 - accuracy: 0.8622\n",
      "Epoch 175/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3200 - accuracy: 0.8638\n",
      "Epoch 176/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3138 - accuracy: 0.8686\n",
      "Epoch 177/200\n",
      "624/624 [==============================] - 0s 135us/step - loss: 0.3121 - accuracy: 0.8670\n",
      "Epoch 178/200\n",
      "624/624 [==============================] - 0s 100us/step - loss: 0.3116 - accuracy: 0.8702\n",
      "Epoch 179/200\n",
      "624/624 [==============================] - 0s 125us/step - loss: 0.3152 - accuracy: 0.8638\n",
      "Epoch 180/200\n",
      "624/624 [==============================] - 0s 126us/step - loss: 0.3119 - accuracy: 0.8782\n",
      "Epoch 181/200\n",
      "624/624 [==============================] - 0s 162us/step - loss: 0.3124 - accuracy: 0.8718\n",
      "Epoch 182/200\n",
      "624/624 [==============================] - 0s 146us/step - loss: 0.3124 - accuracy: 0.8686\n",
      "Epoch 183/200\n",
      "624/624 [==============================] - 0s 133us/step - loss: 0.3112 - accuracy: 0.8766\n",
      "Epoch 184/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3131 - accuracy: 0.8686\n",
      "Epoch 185/200\n",
      "624/624 [==============================] - 0s 152us/step - loss: 0.3107 - accuracy: 0.8734\n",
      "Epoch 186/200\n",
      "624/624 [==============================] - 0s 162us/step - loss: 0.3140 - accuracy: 0.8718\n",
      "Epoch 187/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3111 - accuracy: 0.8670\n",
      "Epoch 188/200\n",
      "624/624 [==============================] - 0s 143us/step - loss: 0.3103 - accuracy: 0.8734\n",
      "Epoch 189/200\n",
      "624/624 [==============================] - 0s 142us/step - loss: 0.3111 - accuracy: 0.8702\n",
      "Epoch 190/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3099 - accuracy: 0.8734\n",
      "Epoch 191/200\n",
      "624/624 [==============================] - 0s 141us/step - loss: 0.3093 - accuracy: 0.8750\n",
      "Epoch 192/200\n",
      "624/624 [==============================] - 0s 141us/step - loss: 0.3106 - accuracy: 0.8750\n",
      "Epoch 193/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3092 - accuracy: 0.8766\n",
      "Epoch 194/200\n",
      "624/624 [==============================] - 0s 135us/step - loss: 0.3097 - accuracy: 0.8702\n",
      "Epoch 195/200\n",
      "624/624 [==============================] - 0s 138us/step - loss: 0.3086 - accuracy: 0.8686\n",
      "Epoch 196/200\n",
      "624/624 [==============================] - 0s 135us/step - loss: 0.3098 - accuracy: 0.8766\n",
      "Epoch 197/200\n",
      "624/624 [==============================] - 0s 156us/step - loss: 0.3078 - accuracy: 0.8766\n",
      "Epoch 198/200\n",
      "624/624 [==============================] - 0s 181us/step - loss: 0.3109 - accuracy: 0.8654\n",
      "Epoch 199/200\n",
      "624/624 [==============================] - 0s 128us/step - loss: 0.3079 - accuracy: 0.8686\n",
      "Epoch 200/200\n",
      "624/624 [==============================] - 0s 140us/step - loss: 0.3080 - accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer ='adam' , loss ='categorical_crossentropy',metrics =['accuracy'] )\n",
    "\n",
    "history=classifier.fit(X_train,y_train,batch_size = 10 ,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 1, 1, 2, 0, 0, 2, 0, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 0,\n",
       "       1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 0,\n",
       "       0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 2, 0, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 2,\n",
       "       2, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1, 0, 0, 0, 0,\n",
       "       2, 2, 1, 1, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 1,\n",
       "       1, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 2, 0, 1, 0,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 699    2\n",
       "327    1\n",
       "210    0\n",
       "14     0\n",
       "413    1\n",
       "428    1\n",
       "585    2\n",
       "561    2\n",
       "214    0\n",
       "630    2\n",
       "31     0\n",
       "434    1\n",
       "644    2\n",
       "665    2\n",
       "103    0\n",
       "592    2\n",
       "306    1\n",
       "432    1\n",
       "222    0\n",
       "419    1\n",
       "650    2\n",
       "175    0\n",
       "312    1\n",
       "698    2\n",
       "27     0\n",
       "605    2\n",
       "531    2\n",
       "749    2\n",
       "689    2\n",
       "534    2\n",
       "      ..\n",
       "255    0\n",
       "489    1\n",
       "204    0\n",
       "737    2\n",
       "706    2\n",
       "196    0\n",
       "500    1\n",
       "390    1\n",
       "718    2\n",
       "71     0\n",
       "49     0\n",
       "266    1\n",
       "142    0\n",
       "535    2\n",
       "37     0\n",
       "231    0\n",
       "48     0\n",
       "546    2\n",
       "317    1\n",
       "346    1\n",
       "751    2\n",
       "647    2\n",
       "76     0\n",
       "64     0\n",
       "620    2\n",
       "52     0\n",
       "318    1\n",
       "602    2\n",
       "494    1\n",
       "352    1\n",
       "Name: class, Length: 156, dtype: int64>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {'merger':0,'elliptical':1,'spiral':2}\n",
    "y_test = y_test.iloc[:,0].map(space)\n",
    "y_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  6,  6],\n",
       "       [ 2, 50,  1],\n",
       "       [ 7,  0, 48]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcf4e5b0d68>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.heatmap(cm,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 1ms/step\n",
      "test acc :0.8589743375778198\n"
     ]
    }
   ],
   "source": [
    "y_test = to_categorical(y_test,3)\n",
    "\n",
    "score = classifier.evaluate(X_test,y_test)\n",
    "print('test acc :{}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
